api:
  default_model_google: gemini-2.5-pro
  default_model_openai: o3
  openai_base_url: null
  openai_timeout: 60
  custom_model_name: null
  custom_model_base_url: null
  custom_model_api_key: null
  custom_model_temperature: 0.1
  custom_model_max_tokens: 32000
  custom_model_timeout: 600
  custom_model_client_timeout: 660
  disable_proxy: false
  max_concurrent_requests: 300
  max_requests_per_minute: 600
data:
  generated_dir: ./data/generated
  output_dir: ./data/output
phase1:
  complexity_distribution:
    easy: 0.25
    expert: 0.25
    hard: 0.25
    medium: 0.25
  projects_per_language: 100
  supported_languages:
  - python
  - cpp
  - java
  - c
  - csharp
  - javascript
  - typescript
  - go
  - rust
  - php
phase2:
  max_complexity_score: 1.0
  max_files_per_project: 100
  min_complexity_score: 0.3
  min_documentation_ratio: 0.01
  min_files_per_project: 10
phase3:
  context_ranges:
    easy:
    - 10000
    - 100000
    expert:
    - 500000
    - 1000000
    hard:
    - 200000
    - 500000
    medium:
    - 100000
    - 200000
  coverage_ranges:
    easy:
    - 0.2
    - 0.4
    expert:
    - 0.8
    - 1.0
    hard:
    - 0.6
    - 0.8
    medium:
    - 0.4
    - 0.6
  difficulty_distribution:
    easy: 2000
    expert: 2000
    hard: 2000
    medium: 2000
  min_information_coverage: 0.2
  task_distribution:
    architectural_understanding: 1000
    bug_investigation: 1000
    code_comprehension: 1000
    cross_file_refactoring: 1000
    feature_implementation: 1000
    integration_testing: 1000
    multi_session_development: 1000
    security_analysis: 1000
  total_instances: 8000
phase4:
  longcontext_utilization_weights:
    information_coverage: 0.5
    multi_session_memory: 0.5
  metric_weights:
    code_quality: 0.2
    functional_correctness: 0.3
    longcontext_utilization: 0.1
    software_engineering: 0.4
  score_thresholds:
    excellent:
      max: 5.0
      min: 4.0
    fair:
      max: 3.0
      min: 2.0
    good:
      max: 4.0
      min: 3.0
    poor:
      max: 2.0
      min: 0.0
  session_timeout: 3600
  software_engineering_weights:
    architectural_coherence: 0.125
    comprehensiveness: 0.125
    cross_file_reasoning: 0.125
    dependency_traversal: 0.125
    innovation: 0.125
    robustness: 0.125
    solution_elegance: 0.125
    system_thinking: 0.125
  task_timeout: 1800
  retrieval:
    chunk_size: 512
    difficulties:
      - hard
      - expert
    enabled: true
    top_percent: 0.05
    max_context_tokens: 4096
    method: embedding
    model_name: all-MiniLM-L6-v2
    local_model_path: null
    top_k: 5
